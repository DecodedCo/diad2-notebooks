{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credit Card Fraud - Jupyter Notebook\n",
    "# COMPLETED\n",
    "<br><br>\n",
    "<b>Notebook objective:</b> build a machine learning fraud detection engine in Python\n",
    "\n",
    "<h2 style=\"background-color:yellow; text-align:center\"><br>Step 1: Python intro<br></h2>\n",
    "<br>\n",
    "To introduce you to coding in Python, you're going to run code that prints \"Hello World!\"\n",
    "<br><br>\n",
    "<mark>Click in the gray cell below and hit Shift + Enter to run the code. If it works, edit the code and re-run it to make it print out your name!</mark>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<h2 style=\"background-color:Tomato; text-align:center\"><br>Step 2: Loading the dataset<br></h2>\n",
    "<br><br>\n",
    "Our dataset, <em>creditcard_data.csv</em> is stored in the folder <em>data</em>, which is in the same folder as this notebook. \n",
    "<br>That means the \"filepath\" from here is <b><em>data/creditcard_data.csv</em></b>.\n",
    "\n",
    "We need to load that data with Python code into a variable. How do we do that?\n",
    "\n",
    "With a bit of googling it looks like the easiest way out there is to use a library of pre-written Python code called [PANDAS](https://www.google.com/search?q=load+csv+in+python+with+pandas&oq=load+csv+in+python+with+pandas&aqs=chrome..69i57j0l7.5608j1j9&sourceid=chrome&ie=UTF-8) (Python AND DAta Science) made to make working with data in Python easier.\n",
    "\n",
    "<mark>Read the code below and try to understand what it is doing (it's ok not to understand every detail). Change INSERT_FILEPATH to the correct filepath and run the code (keep the quotation marks!). If you do it correctly, you will get no error.</mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"../data/creditcard_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have now stored the data inside a variable called <em>data</em>, but we can't see it! Searching online, we can find simple PANDAS code to help us.\n",
    "\n",
    "<mark>Run <b>data.head(5)</b> in the cell below to see the top (head) 5 rows of the data (feel free to experiment with the number). Scroll left and right to see all the columns.</mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fraud</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>...</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6398.0</td>\n",
       "      <td>-2.380210</td>\n",
       "      <td>-0.266473</td>\n",
       "      <td>1.090077</td>\n",
       "      <td>0.853215</td>\n",
       "      <td>3.371780</td>\n",
       "      <td>3.790719</td>\n",
       "      <td>-1.123674</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.223553</td>\n",
       "      <td>-0.671187</td>\n",
       "      <td>-0.306571</td>\n",
       "      <td>-0.514617</td>\n",
       "      <td>-0.443708</td>\n",
       "      <td>0.962374</td>\n",
       "      <td>0.088245</td>\n",
       "      <td>-0.280859</td>\n",
       "      <td>-0.635895</td>\n",
       "      <td>0.616903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>168.08</td>\n",
       "      <td>144368.0</td>\n",
       "      <td>-0.501770</td>\n",
       "      <td>0.512773</td>\n",
       "      <td>-0.494351</td>\n",
       "      <td>-0.657718</td>\n",
       "      <td>0.695019</td>\n",
       "      <td>0.974452</td>\n",
       "      <td>1.482355</td>\n",
       "      <td>...</td>\n",
       "      <td>1.298452</td>\n",
       "      <td>-0.274723</td>\n",
       "      <td>-0.001963</td>\n",
       "      <td>0.251114</td>\n",
       "      <td>-0.169487</td>\n",
       "      <td>-0.454563</td>\n",
       "      <td>-0.184577</td>\n",
       "      <td>-0.298358</td>\n",
       "      <td>0.042771</td>\n",
       "      <td>0.108608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6.63</td>\n",
       "      <td>48330.0</td>\n",
       "      <td>-2.031128</td>\n",
       "      <td>1.253731</td>\n",
       "      <td>1.070599</td>\n",
       "      <td>0.359631</td>\n",
       "      <td>0.434048</td>\n",
       "      <td>-0.799150</td>\n",
       "      <td>1.256107</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.154391</td>\n",
       "      <td>-0.288509</td>\n",
       "      <td>0.059160</td>\n",
       "      <td>0.424752</td>\n",
       "      <td>-0.304448</td>\n",
       "      <td>0.413236</td>\n",
       "      <td>0.080387</td>\n",
       "      <td>-0.636258</td>\n",
       "      <td>-2.489246</td>\n",
       "      <td>-0.544980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>10.07</td>\n",
       "      <td>13291.0</td>\n",
       "      <td>-1.194486</td>\n",
       "      <td>0.917545</td>\n",
       "      <td>1.769059</td>\n",
       "      <td>-0.833028</td>\n",
       "      <td>-0.296318</td>\n",
       "      <td>-0.324340</td>\n",
       "      <td>-0.159088</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.906351</td>\n",
       "      <td>-0.058228</td>\n",
       "      <td>-0.151858</td>\n",
       "      <td>-0.358540</td>\n",
       "      <td>0.082015</td>\n",
       "      <td>0.180577</td>\n",
       "      <td>-0.488772</td>\n",
       "      <td>0.615896</td>\n",
       "      <td>0.119299</td>\n",
       "      <td>0.061904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>49.08</td>\n",
       "      <td>24430.0</td>\n",
       "      <td>-1.258770</td>\n",
       "      <td>1.011808</td>\n",
       "      <td>1.134976</td>\n",
       "      <td>-1.716026</td>\n",
       "      <td>0.025043</td>\n",
       "      <td>-1.145037</td>\n",
       "      <td>1.170804</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.910318</td>\n",
       "      <td>0.032569</td>\n",
       "      <td>-0.295435</td>\n",
       "      <td>-0.087037</td>\n",
       "      <td>0.206569</td>\n",
       "      <td>0.362216</td>\n",
       "      <td>-1.164668</td>\n",
       "      <td>0.273269</td>\n",
       "      <td>-0.315072</td>\n",
       "      <td>0.040467</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Fraud  Amount      Time        V1        V2        V3        V4        V5  \\\n",
       "0      0    0.00    6398.0 -2.380210 -0.266473  1.090077  0.853215  3.371780   \n",
       "1      0  168.08  144368.0 -0.501770  0.512773 -0.494351 -0.657718  0.695019   \n",
       "2      0    6.63   48330.0 -2.031128  1.253731  1.070599  0.359631  0.434048   \n",
       "3      0   10.07   13291.0 -1.194486  0.917545  1.769059 -0.833028 -0.296318   \n",
       "4      0   49.08   24430.0 -1.258770  1.011808  1.134976 -1.716026  0.025043   \n",
       "\n",
       "         V6        V7  ...       V19       V20       V21       V22       V23  \\\n",
       "0  3.790719 -1.123674  ... -1.223553 -0.671187 -0.306571 -0.514617 -0.443708   \n",
       "1  0.974452  1.482355  ...  1.298452 -0.274723 -0.001963  0.251114 -0.169487   \n",
       "2 -0.799150  1.256107  ... -0.154391 -0.288509  0.059160  0.424752 -0.304448   \n",
       "3 -0.324340 -0.159088  ... -0.906351 -0.058228 -0.151858 -0.358540  0.082015   \n",
       "4 -1.145037  1.170804  ... -1.910318  0.032569 -0.295435 -0.087037  0.206569   \n",
       "\n",
       "        V24       V25       V26       V27       V28  \n",
       "0  0.962374  0.088245 -0.280859 -0.635895  0.616903  \n",
       "1 -0.454563 -0.184577 -0.298358  0.042771  0.108608  \n",
       "2  0.413236  0.080387 -0.636258 -2.489246 -0.544980  \n",
       "3  0.180577 -0.488772  0.615896  0.119299  0.061904  \n",
       "4  0.362216 -1.164668  0.273269 -0.315072  0.040467  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notice how many column headers are anonymized (V1, V2 etc..) - this mimics what Mastercard sees in Decision Intelligence. Since our model will learn using correlations, it doesn't need to know what each number represents.**\n",
    "\n",
    "<mark>Run <b>data.describe()</b> in the cell below to see a summary of the entire dataset. What is the average amount of the transactions in this dataset?</mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fraud</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>...</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>179807.000000</td>\n",
       "      <td>179807.000000</td>\n",
       "      <td>179807.000000</td>\n",
       "      <td>179807.000000</td>\n",
       "      <td>179807.000000</td>\n",
       "      <td>179807.000000</td>\n",
       "      <td>179807.000000</td>\n",
       "      <td>179807.000000</td>\n",
       "      <td>179807.000000</td>\n",
       "      <td>179807.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>179807.000000</td>\n",
       "      <td>179807.000000</td>\n",
       "      <td>179807.000000</td>\n",
       "      <td>179807.000000</td>\n",
       "      <td>179807.000000</td>\n",
       "      <td>179807.000000</td>\n",
       "      <td>179807.000000</td>\n",
       "      <td>179807.000000</td>\n",
       "      <td>179807.000000</td>\n",
       "      <td>179807.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>0.002736</td>\n",
       "      <td>88.691655</td>\n",
       "      <td>94852.147514</td>\n",
       "      <td>-0.008439</td>\n",
       "      <td>0.005504</td>\n",
       "      <td>-0.010693</td>\n",
       "      <td>0.003398</td>\n",
       "      <td>-0.003956</td>\n",
       "      <td>-0.001342</td>\n",
       "      <td>-0.004055</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000196</td>\n",
       "      <td>0.001023</td>\n",
       "      <td>-0.000759</td>\n",
       "      <td>0.000299</td>\n",
       "      <td>-0.000854</td>\n",
       "      <td>-0.000885</td>\n",
       "      <td>0.000234</td>\n",
       "      <td>0.000931</td>\n",
       "      <td>0.000379</td>\n",
       "      <td>-0.000530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>0.052238</td>\n",
       "      <td>256.780747</td>\n",
       "      <td>47511.317469</td>\n",
       "      <td>1.990363</td>\n",
       "      <td>1.672807</td>\n",
       "      <td>1.557383</td>\n",
       "      <td>1.427128</td>\n",
       "      <td>1.408462</td>\n",
       "      <td>1.339708</td>\n",
       "      <td>1.290396</td>\n",
       "      <td>...</td>\n",
       "      <td>0.816032</td>\n",
       "      <td>0.786039</td>\n",
       "      <td>0.747883</td>\n",
       "      <td>0.727345</td>\n",
       "      <td>0.622993</td>\n",
       "      <td>0.605972</td>\n",
       "      <td>0.521215</td>\n",
       "      <td>0.483004</td>\n",
       "      <td>0.408920</td>\n",
       "      <td>0.333813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-56.407510</td>\n",
       "      <td>-72.715728</td>\n",
       "      <td>-48.325589</td>\n",
       "      <td>-5.600607</td>\n",
       "      <td>-113.743307</td>\n",
       "      <td>-26.160506</td>\n",
       "      <td>-43.557242</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.213527</td>\n",
       "      <td>-54.497720</td>\n",
       "      <td>-34.830382</td>\n",
       "      <td>-10.933144</td>\n",
       "      <td>-32.828995</td>\n",
       "      <td>-2.836627</td>\n",
       "      <td>-8.696627</td>\n",
       "      <td>-2.604551</td>\n",
       "      <td>-9.895244</td>\n",
       "      <td>-15.430084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.590000</td>\n",
       "      <td>54197.500000</td>\n",
       "      <td>-0.922073</td>\n",
       "      <td>-0.597506</td>\n",
       "      <td>-0.894809</td>\n",
       "      <td>-0.849089</td>\n",
       "      <td>-0.693350</td>\n",
       "      <td>-0.770329</td>\n",
       "      <td>-0.555703</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.455127</td>\n",
       "      <td>-0.211652</td>\n",
       "      <td>-0.228478</td>\n",
       "      <td>-0.543265</td>\n",
       "      <td>-0.162106</td>\n",
       "      <td>-0.355531</td>\n",
       "      <td>-0.316732</td>\n",
       "      <td>-0.326259</td>\n",
       "      <td>-0.071221</td>\n",
       "      <td>-0.053356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>84730.000000</td>\n",
       "      <td>0.013052</td>\n",
       "      <td>0.066827</td>\n",
       "      <td>0.175026</td>\n",
       "      <td>-0.018199</td>\n",
       "      <td>-0.053101</td>\n",
       "      <td>-0.276379</td>\n",
       "      <td>0.040783</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004523</td>\n",
       "      <td>-0.061435</td>\n",
       "      <td>-0.029734</td>\n",
       "      <td>0.007104</td>\n",
       "      <td>-0.011208</td>\n",
       "      <td>0.040260</td>\n",
       "      <td>0.014645</td>\n",
       "      <td>-0.051627</td>\n",
       "      <td>0.001256</td>\n",
       "      <td>0.011036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>77.525000</td>\n",
       "      <td>139459.000000</td>\n",
       "      <td>1.315338</td>\n",
       "      <td>0.807438</td>\n",
       "      <td>1.028009</td>\n",
       "      <td>0.745151</td>\n",
       "      <td>0.614137</td>\n",
       "      <td>0.400072</td>\n",
       "      <td>0.573418</td>\n",
       "      <td>...</td>\n",
       "      <td>0.459585</td>\n",
       "      <td>0.134985</td>\n",
       "      <td>0.186511</td>\n",
       "      <td>0.531050</td>\n",
       "      <td>0.147933</td>\n",
       "      <td>0.439650</td>\n",
       "      <td>0.349949</td>\n",
       "      <td>0.242213</td>\n",
       "      <td>0.091210</td>\n",
       "      <td>0.078259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>25691.160000</td>\n",
       "      <td>172788.000000</td>\n",
       "      <td>2.454930</td>\n",
       "      <td>22.057729</td>\n",
       "      <td>4.226108</td>\n",
       "      <td>16.875344</td>\n",
       "      <td>34.801666</td>\n",
       "      <td>73.301626</td>\n",
       "      <td>120.589494</td>\n",
       "      <td>...</td>\n",
       "      <td>5.591971</td>\n",
       "      <td>39.420904</td>\n",
       "      <td>27.202839</td>\n",
       "      <td>10.503090</td>\n",
       "      <td>22.528412</td>\n",
       "      <td>4.584549</td>\n",
       "      <td>7.519589</td>\n",
       "      <td>3.517346</td>\n",
       "      <td>31.612198</td>\n",
       "      <td>33.847808</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Fraud         Amount           Time             V1  \\\n",
       "count  179807.000000  179807.000000  179807.000000  179807.000000   \n",
       "mean        0.002736      88.691655   94852.147514      -0.008439   \n",
       "std         0.052238     256.780747   47511.317469       1.990363   \n",
       "min         0.000000       0.000000       0.000000     -56.407510   \n",
       "25%         0.000000       5.590000   54197.500000      -0.922073   \n",
       "50%         0.000000      22.000000   84730.000000       0.013052   \n",
       "75%         0.000000      77.525000  139459.000000       1.315338   \n",
       "max         1.000000   25691.160000  172788.000000       2.454930   \n",
       "\n",
       "                  V2             V3             V4             V5  \\\n",
       "count  179807.000000  179807.000000  179807.000000  179807.000000   \n",
       "mean        0.005504      -0.010693       0.003398      -0.003956   \n",
       "std         1.672807       1.557383       1.427128       1.408462   \n",
       "min       -72.715728     -48.325589      -5.600607    -113.743307   \n",
       "25%        -0.597506      -0.894809      -0.849089      -0.693350   \n",
       "50%         0.066827       0.175026      -0.018199      -0.053101   \n",
       "75%         0.807438       1.028009       0.745151       0.614137   \n",
       "max        22.057729       4.226108      16.875344      34.801666   \n",
       "\n",
       "                  V6             V7  ...            V19            V20  \\\n",
       "count  179807.000000  179807.000000  ...  179807.000000  179807.000000   \n",
       "mean       -0.001342      -0.004055  ...       0.000196       0.001023   \n",
       "std         1.339708       1.290396  ...       0.816032       0.786039   \n",
       "min       -26.160506     -43.557242  ...      -7.213527     -54.497720   \n",
       "25%        -0.770329      -0.555703  ...      -0.455127      -0.211652   \n",
       "50%        -0.276379       0.040783  ...       0.004523      -0.061435   \n",
       "75%         0.400072       0.573418  ...       0.459585       0.134985   \n",
       "max        73.301626     120.589494  ...       5.591971      39.420904   \n",
       "\n",
       "                 V21            V22            V23            V24  \\\n",
       "count  179807.000000  179807.000000  179807.000000  179807.000000   \n",
       "mean       -0.000759       0.000299      -0.000854      -0.000885   \n",
       "std         0.747883       0.727345       0.622993       0.605972   \n",
       "min       -34.830382     -10.933144     -32.828995      -2.836627   \n",
       "25%        -0.228478      -0.543265      -0.162106      -0.355531   \n",
       "50%        -0.029734       0.007104      -0.011208       0.040260   \n",
       "75%         0.186511       0.531050       0.147933       0.439650   \n",
       "max        27.202839      10.503090      22.528412       4.584549   \n",
       "\n",
       "                 V25            V26            V27            V28  \n",
       "count  179807.000000  179807.000000  179807.000000  179807.000000  \n",
       "mean        0.000234       0.000931       0.000379      -0.000530  \n",
       "std         0.521215       0.483004       0.408920       0.333813  \n",
       "min        -8.696627      -2.604551      -9.895244     -15.430084  \n",
       "25%        -0.316732      -0.326259      -0.071221      -0.053356  \n",
       "50%         0.014645      -0.051627       0.001256       0.011036  \n",
       "75%         0.349949       0.242213       0.091210       0.078259  \n",
       "max         7.519589       3.517346      31.612198      33.847808  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<mark>While waiting for the facilitator to move on to the next section, discuss the following two questions with your partner:</mark>\n",
    "\n",
    "1. Our ability to make good predictions depends on the data we use -- what differences might you expect between the model we will make based on this dataset and models built on more recent data?\n",
    "<br><br>\n",
    "2. Why do you think it is useful to have anonymized columns?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<h2 style=\"background-color:DodgerBlue; text-align:center\"><br>Step 3: Building our model<br></h2>\n",
    "<br>\n",
    "<b>Mastercard uses a variety of types models to detect fraud. As you know, one of them is decision trees.</b>\n",
    "\n",
    "Today, we will build a decision tree that is able to predict whether a certain transaction is fraudulent based on the data available to us.\n",
    "\n",
    "Again, we won't start from scratch; we'll use a data science toolkit called [sklearn](https://scikit-learn.org/stable/modules/tree.html), but we'll need to specify what data we are using as input and which column we want to predict as output.\n",
    "\n",
    "<mark>Read the code below and try to understand what it is doing. The gray text after \"#\" are comments - little bits of text to explain the code, they don't do anything. Once you're happy, run the code and hope for no errors!</mark> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "# Use all data except the 'Fraud' column as input\n",
    "X = data.drop('Fraud', axis=1)\n",
    "# Use the 'Class' column as what we want to predict as output\n",
    "y = data['Fraud']\n",
    "\n",
    "# Create an empty model \n",
    "model = tree.DecisionTreeClassifier()\n",
    "\n",
    "# Fit the model to our data\n",
    "model = model.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<h2 style=\"background-color:MediumSeaGreen; text-align:center\"><br>Step 4: Evaluating our model<br></h2>\n",
    "<br>\n",
    "\n",
    "We've built our tree -- now let's test it.\n",
    "\n",
    "<mark>In the cell below, use **model.score(X, y)** to evaluate the accuracy of our tree using our input and output data.</mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy ranges between 0.0 (it predicted every transaction wrong) to 1.0 (it predicted every transaction right).\n",
    "\n",
    "<mark>Look at your accuracy and discuss with your partner: is it possible to be too accurate?</mark>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model iteration\n",
    "\n",
    "Just like much of writing is reading and re-writing, when data scientists test their models, they analyze the results and re-build the models.\n",
    "\n",
    "<mark>Run the code below to split the data into training X and y and test X and Y</mark>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split X and y (our input and outputs) into training and testing datasets.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=99)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the code we used to build the model before.\n",
    "\n",
    "<mark>Modify and run it to use your training and testing datasets.</mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9987208720315889"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tree.DecisionTreeClassifier()\n",
    "model = model.fit(X_train, y_train)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, what might explain the accuracy score of your model?\n",
    "\n",
    "<mark>Run the code below and interpret the results. What problem is this showing?</mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    179315\n",
      "1       492\n",
      "Name: Fraud, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x11f9409d0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "counts = pd.value_counts(data['Fraud'])\n",
    "\n",
    "%matplotlib inline\n",
    "print(counts)\n",
    "counts.plot(kind=\"bar\",\n",
    "           title=\"Frequency of Genuine vs Fraudulent Transactions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why is this a problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforming the data\n",
    "\n",
    "**Data scientists make choices that impact model outputs. At Mastercard, data scientists are dealing with the same challenge: trying to reduce fraud based on limited datasets.**\n",
    "\n",
    "To deal with the uneven number of fraud and genuine transactions, we could artificially increase the number of fraud transactions by creating similar transactions, or we could reduce the number of genuine transactions.\n",
    "\n",
    "With more time, we might test multiple strategies. Today we'll reduce the number of genuine transactions.\n",
    "\n",
    "<mark>Run the code, and look at the mean of the Class column. What does it mean? Modify number_genuine to change the number of genuine transactions that balance the classes, and re-run the code.</mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fraud</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>...</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>984.000000</td>\n",
       "      <td>984.000000</td>\n",
       "      <td>984.000000</td>\n",
       "      <td>984.000000</td>\n",
       "      <td>984.000000</td>\n",
       "      <td>984.000000</td>\n",
       "      <td>984.000000</td>\n",
       "      <td>984.000000</td>\n",
       "      <td>984.000000</td>\n",
       "      <td>984.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>984.000000</td>\n",
       "      <td>984.000000</td>\n",
       "      <td>984.000000</td>\n",
       "      <td>984.000000</td>\n",
       "      <td>984.000000</td>\n",
       "      <td>984.000000</td>\n",
       "      <td>984.000000</td>\n",
       "      <td>984.000000</td>\n",
       "      <td>984.000000</td>\n",
       "      <td>984.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>105.625549</td>\n",
       "      <td>87772.773374</td>\n",
       "      <td>-2.329518</td>\n",
       "      <td>1.823507</td>\n",
       "      <td>-3.511732</td>\n",
       "      <td>2.259751</td>\n",
       "      <td>-1.621856</td>\n",
       "      <td>-0.701799</td>\n",
       "      <td>-2.758683</td>\n",
       "      <td>...</td>\n",
       "      <td>0.331004</td>\n",
       "      <td>0.181716</td>\n",
       "      <td>0.353095</td>\n",
       "      <td>-0.013729</td>\n",
       "      <td>-0.014311</td>\n",
       "      <td>-0.039749</td>\n",
       "      <td>0.014095</td>\n",
       "      <td>0.031061</td>\n",
       "      <td>0.087634</td>\n",
       "      <td>0.035255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>0.500254</td>\n",
       "      <td>229.947832</td>\n",
       "      <td>48598.721123</td>\n",
       "      <td>5.541516</td>\n",
       "      <td>3.688949</td>\n",
       "      <td>6.223185</td>\n",
       "      <td>3.207252</td>\n",
       "      <td>4.181589</td>\n",
       "      <td>1.721862</td>\n",
       "      <td>5.873621</td>\n",
       "      <td>...</td>\n",
       "      <td>1.266603</td>\n",
       "      <td>1.106476</td>\n",
       "      <td>2.804156</td>\n",
       "      <td>1.171111</td>\n",
       "      <td>1.160439</td>\n",
       "      <td>0.546420</td>\n",
       "      <td>0.670117</td>\n",
       "      <td>0.475559</td>\n",
       "      <td>1.005875</td>\n",
       "      <td>0.419357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>-30.552380</td>\n",
       "      <td>-18.955081</td>\n",
       "      <td>-31.103685</td>\n",
       "      <td>-3.333103</td>\n",
       "      <td>-22.105532</td>\n",
       "      <td>-6.406267</td>\n",
       "      <td>-43.557242</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.681904</td>\n",
       "      <td>-11.485230</td>\n",
       "      <td>-22.797604</td>\n",
       "      <td>-8.887017</td>\n",
       "      <td>-19.254328</td>\n",
       "      <td>-2.381726</td>\n",
       "      <td>-4.781606</td>\n",
       "      <td>-1.152671</td>\n",
       "      <td>-7.263482</td>\n",
       "      <td>-2.285577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.417500</td>\n",
       "      <td>46166.250000</td>\n",
       "      <td>-2.752488</td>\n",
       "      <td>-0.148638</td>\n",
       "      <td>-5.113334</td>\n",
       "      <td>-0.126321</td>\n",
       "      <td>-1.903853</td>\n",
       "      <td>-1.536701</td>\n",
       "      <td>-3.044451</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.389864</td>\n",
       "      <td>-0.191266</td>\n",
       "      <td>-0.182621</td>\n",
       "      <td>-0.562902</td>\n",
       "      <td>-0.236618</td>\n",
       "      <td>-0.382099</td>\n",
       "      <td>-0.308706</td>\n",
       "      <td>-0.283741</td>\n",
       "      <td>-0.065071</td>\n",
       "      <td>-0.059272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>19.840000</td>\n",
       "      <td>79367.500000</td>\n",
       "      <td>-0.708867</td>\n",
       "      <td>0.959237</td>\n",
       "      <td>-1.385429</td>\n",
       "      <td>1.341077</td>\n",
       "      <td>-0.463951</td>\n",
       "      <td>-0.620498</td>\n",
       "      <td>-0.660534</td>\n",
       "      <td>...</td>\n",
       "      <td>0.215332</td>\n",
       "      <td>0.026022</td>\n",
       "      <td>0.150551</td>\n",
       "      <td>0.010270</td>\n",
       "      <td>-0.025073</td>\n",
       "      <td>0.002041</td>\n",
       "      <td>0.049648</td>\n",
       "      <td>-0.010831</td>\n",
       "      <td>0.046272</td>\n",
       "      <td>0.035133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>99.990000</td>\n",
       "      <td>136068.750000</td>\n",
       "      <td>1.074926</td>\n",
       "      <td>2.798885</td>\n",
       "      <td>0.342011</td>\n",
       "      <td>4.235631</td>\n",
       "      <td>0.435895</td>\n",
       "      <td>0.042146</td>\n",
       "      <td>0.262865</td>\n",
       "      <td>...</td>\n",
       "      <td>0.940760</td>\n",
       "      <td>0.423209</td>\n",
       "      <td>0.645756</td>\n",
       "      <td>0.552176</td>\n",
       "      <td>0.204668</td>\n",
       "      <td>0.367388</td>\n",
       "      <td>0.384911</td>\n",
       "      <td>0.322036</td>\n",
       "      <td>0.455390</td>\n",
       "      <td>0.213326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2125.870000</td>\n",
       "      <td>172700.000000</td>\n",
       "      <td>2.422508</td>\n",
       "      <td>22.057729</td>\n",
       "      <td>3.402585</td>\n",
       "      <td>12.114672</td>\n",
       "      <td>11.095089</td>\n",
       "      <td>6.474115</td>\n",
       "      <td>8.676152</td>\n",
       "      <td>...</td>\n",
       "      <td>5.228342</td>\n",
       "      <td>11.059004</td>\n",
       "      <td>27.202839</td>\n",
       "      <td>8.361985</td>\n",
       "      <td>5.466230</td>\n",
       "      <td>1.204431</td>\n",
       "      <td>2.208209</td>\n",
       "      <td>2.745261</td>\n",
       "      <td>3.052358</td>\n",
       "      <td>1.779364</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Fraud       Amount           Time          V1          V2  \\\n",
       "count  984.000000   984.000000     984.000000  984.000000  984.000000   \n",
       "mean     0.500000   105.625549   87772.773374   -2.329518    1.823507   \n",
       "std      0.500254   229.947832   48598.721123    5.541516    3.688949   \n",
       "min      0.000000     0.000000      55.000000  -30.552380  -18.955081   \n",
       "25%      0.000000     1.417500   46166.250000   -2.752488   -0.148638   \n",
       "50%      0.500000    19.840000   79367.500000   -0.708867    0.959237   \n",
       "75%      1.000000    99.990000  136068.750000    1.074926    2.798885   \n",
       "max      1.000000  2125.870000  172700.000000    2.422508   22.057729   \n",
       "\n",
       "               V3          V4          V5          V6          V7  ...  \\\n",
       "count  984.000000  984.000000  984.000000  984.000000  984.000000  ...   \n",
       "mean    -3.511732    2.259751   -1.621856   -0.701799   -2.758683  ...   \n",
       "std      6.223185    3.207252    4.181589    1.721862    5.873621  ...   \n",
       "min    -31.103685   -3.333103  -22.105532   -6.406267  -43.557242  ...   \n",
       "25%     -5.113334   -0.126321   -1.903853   -1.536701   -3.044451  ...   \n",
       "50%     -1.385429    1.341077   -0.463951   -0.620498   -0.660534  ...   \n",
       "75%      0.342011    4.235631    0.435895    0.042146    0.262865  ...   \n",
       "max      3.402585   12.114672   11.095089    6.474115    8.676152  ...   \n",
       "\n",
       "              V19         V20         V21         V22         V23         V24  \\\n",
       "count  984.000000  984.000000  984.000000  984.000000  984.000000  984.000000   \n",
       "mean     0.331004    0.181716    0.353095   -0.013729   -0.014311   -0.039749   \n",
       "std      1.266603    1.106476    2.804156    1.171111    1.160439    0.546420   \n",
       "min     -3.681904  -11.485230  -22.797604   -8.887017  -19.254328   -2.381726   \n",
       "25%     -0.389864   -0.191266   -0.182621   -0.562902   -0.236618   -0.382099   \n",
       "50%      0.215332    0.026022    0.150551    0.010270   -0.025073    0.002041   \n",
       "75%      0.940760    0.423209    0.645756    0.552176    0.204668    0.367388   \n",
       "max      5.228342   11.059004   27.202839    8.361985    5.466230    1.204431   \n",
       "\n",
       "              V25         V26         V27         V28  \n",
       "count  984.000000  984.000000  984.000000  984.000000  \n",
       "mean     0.014095    0.031061    0.087634    0.035255  \n",
       "std      0.670117    0.475559    1.005875    0.419357  \n",
       "min     -4.781606   -1.152671   -7.263482   -2.285577  \n",
       "25%     -0.308706   -0.283741   -0.065071   -0.059272  \n",
       "50%      0.049648   -0.010831    0.046272    0.035133  \n",
       "75%      0.384911    0.322036    0.455390    0.213326  \n",
       "max      2.208209    2.745261    3.052358    1.779364  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many genuine transactions should we use to balance the classes?\n",
    "number_genuine = 492\n",
    "\n",
    "# Separate genuine transactions and fraud\n",
    "genuine = data[data['Fraud'] == 0].sample(number_genuine)\n",
    "fraud = data[data['Fraud'] == 1]\n",
    "\n",
    "# Combine fraud and genuine\n",
    "even_data = pd.concat([genuine, fraud])\n",
    "\n",
    "# Summarize our new dataset, even_data\n",
    "even_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have a new dataset, we'll need to recreate our inputs, outputs, and split them into training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8986486486486487"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create inputs and outputs with new dataset\n",
    "X = even_data.drop('Fraud', axis=1)\n",
    "y = even_data['Fraud']\n",
    "\n",
    "# Split new inputs and outputs into training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=99)\n",
    "\n",
    "# Train and score decision tree using new data\n",
    "model = tree.DecisionTreeClassifier(max_depth = 4)\n",
    "model = model.fit(X_train, y_train)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last step is to visualize the decision tree we made. To do this, we've copied some code from the sklearn documentation.\n",
    "\n",
    "<mark>Run the code below to see your tree!</mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz\n",
    "dot_data = tree.export_graphviz(model, out_file=None, \n",
    "                     feature_names=X.columns.values,  \n",
    "                     class_names=[\"Genuine\",\"Fraud\"],  \n",
    "                     filled=True, rounded=True, \n",
    "                     special_characters=True)  \n",
    "graph = graphviz.Source(dot_data)  \n",
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might notice your decision tree is very small. The final step is to evaluate how complex your decision tree needs to be.\n",
    "\n",
    "<mark>Go back <b>two</b> code cells and change the max_depth of your decsion tree (line 9). Run the code, then re-run the code to visualize the tree</mark>\n",
    "\n",
    "<mark>What size of decision tree gets the greatest accuracy for your data? Why?</mark>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantifying the investment\n",
    "\n",
    "**Building good models requires time and resources; it is important to focus on valuable investments.**\n",
    "\n",
    "How do you know your time was well spent?\n",
    "\n",
    "There are huge costs associated with accepting a fraudlent transaction; [LexisNexis](https://risk.lexisnexis.com/insights-resources/research/2018-true-cost-of-fraud-study-for-the-retail-sector) finds fraud costs retailers an average of $2.94 per fraudulent dollar in fees, prevention, legal costs, etc. Declining a genuine transaction is costly too! [Ayden and 451 Research](https://go.adyen.com/rs/222-DNK-376/images/Retail%20Report%202019.pdf?mkt_tok=eyJpIjoiWXpNeE56Y3paRGszTnpBNSIsInQiOiJaVmJ1NXVJVkZFMkdHY1FCYVRGUENFemlDWnU3RSthM21LRmF3MDdtUldwSjZvMVF6ZzVjTTFjemJKS1BxZUJWWElxejZrQXVKeDhwNlZGVXkwT3FtcTkwd1BFTkwwaWZlV1BFcnM3YmY2aEQ1RnMrT3BFS1g4MTRsaWI3R1BUSSJ9) report 2 in 5 consumers have abandoned a purchase after a declined payment in the past 6 months. Customers are less likely to return to a merchant after a failed payment.\n",
    "\n",
    "In our simulation, we'll charge $2.94 per dollar for each false approval and the cost of the transaction for each false decline. Of course, every situation is different, and a client will likely have their own costs associated with false approvals and declines.\n",
    "\n",
    "<mark>Run the cell below to compare the cost of fraud when using your model with the cost of approving all transactions.</mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You processed 296 payments. 266 were correct predictions, of which the genuine transactions totalled $12534.45 in revenue.\n",
      "\n",
      "You had 24 false approvals, which cost $10693.63 in fees and administrative costs.\n",
      "You had 6 false declines, which cost $306.31 in missed sales.\n",
      "\n",
      "10.14% of your predictions were incorrect.\n",
      "Your loss due to fraud was 46.74% of revenue.\n",
      "\n",
      "If you had simply approved all 296 transactions, you would have falsely approved 161 transactions, costing $48026.84 while earning $12840.76 in revenue.\n",
      "\n",
      "Your model's predictions were worth $36720.59.\n"
     ]
    }
   ],
   "source": [
    "COST_PER_FRAUD_DOLLAR = 2.94 # Cost per dollar of a false approval\n",
    "COST_PER_FALSE_DECLINE_DOLLAR = 1 # Cost per dollar of a false decline\n",
    "\n",
    "predictions = list(model.predict(X_test))\n",
    "truth = list(y_test)\n",
    "\n",
    "false_approval_cost = 0\n",
    "false_approval_num = 0\n",
    "false_decline_cost = 0\n",
    "false_decline_num = 0\n",
    "correct_num = 0\n",
    "correct_cost = 0\n",
    "\n",
    "for i in range(len(predictions)):\n",
    "    if predictions[i] != truth[i]: # If our prediction was wrong\n",
    "        if truth[i] == 1: # If we falsely approved\n",
    "            false_approval_cost += (X_test.iloc[i, 0] * COST_PER_FRAUD_DOLLAR) # Cost increases by $2.94 * the amount of the transaction\n",
    "            false_approval_num += 1\n",
    "        else: # If we falsely decline\n",
    "            false_decline_cost += (X_test.iloc[i, 0] * COST_PER_FALSE_DECLINE_DOLLAR) # We miss a sale, cost increases by the amount of the transaction\n",
    "            false_decline_num += 1\n",
    "    else: # If our prediction was correct\n",
    "        correct_num += 1\n",
    "        if truth[i] == 0: # It's a genuine transaction\n",
    "            correct_cost += X_test.iloc[i, 0]\n",
    "\n",
    "print(\"You processed {} payments. {} were correct predictions, of which the genuine transactions totalled ${} in revenue.\\n\\nYou had {} false approvals, which cost ${} in fees and administrative costs.\\nYou had {} false declines, which cost ${} in missed sales.\\n\".format(len(predictions), correct_num, round(correct_cost,2),  false_approval_num, round(false_approval_cost, 2), false_decline_num, round(false_decline_cost,2)))\n",
    "print(\"{}% of your predictions were incorrect.\\nYour loss due to fraud was {}% of revenue.\\n\".format(round((false_approval_num+false_decline_num)*100/len(predictions),2), round((false_approval_cost+false_decline_cost)/(false_approval_cost+false_decline_cost+correct_cost)*100,2)))\n",
    "\n",
    "approve_all_cost = 0\n",
    "approve_all_num = 0\n",
    "all_genuine_cost = 0\n",
    "\n",
    "for i in range(len(truth)):\n",
    "    if truth[i] == 1: # There was fraud\n",
    "        approve_all_cost += (X_test.iloc[i, 0] * COST_PER_FRAUD_DOLLAR)\n",
    "        approve_all_num += 1\n",
    "    else: # Genuine transaction\n",
    "        all_genuine_cost += X_test.iloc[i, 0]\n",
    "\n",
    "print(\"If you had simply approved all {} transactions, you would have falsely approved {} transactions, costing ${} while earning ${} in revenue.\\n\".format(len(predictions), approve_all_num, round(approve_all_cost, 2), round(all_genuine_cost, 2)))\n",
    "print(\"Your model's predictions were worth ${}.\".format(round(((correct_cost - false_decline_cost - false_approval_cost)-(all_genuine_cost - approve_all_cost)),2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<mark>What differs in our simulation when compared to reality?</mark>\n",
    "\n",
    "<mark>What could make our model stronger?</mark>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
