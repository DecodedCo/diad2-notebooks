{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credit Card Fraud - Jupyter Notebook\n",
    "<br><br>\n",
    "<b>Notebook objective:</b> build a machine learning fraud detection engine in Python\n",
    "\n",
    "<h2 style=\"background-color:DarkCyan; text-align:center\"><br>Step 1: Python intro<br></h2>\n",
    "<br>\n",
    "To introduce you to coding in Python, you're going to run code that prints \"Hello World!\"\n",
    "<br><br>\n",
    "<mark>Click in the gray cell below and hit Shift + Enter to run the code. If it works, you will see text printed out beneath the cell. Edit the code and re-run it to make it print out your name!</mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Hello World!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"background-color:Tomato; text-align:center\"><br>Step 2: Loading the dataset<br></h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to read in our csv file of data. To do this with raw Python, we'd have to write a lot of code. Fortunately, someone ([Wes Mckinney](https://wesmckinney.com/pages/about.html)) created a \"library\" of Python code that packages up all that code in to a simple function. The library is called Pandas (Python ANd Data Science), which we can import and give a short nickname (\"pd\").\n",
    "<br><br>\n",
    "<mark>Run the code below, without editing it, the same way you did above. If everything works you will get a number next to the cell, and no error.</mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"data/creditcard_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<mark>Run the code below to see the top (\"head\") 5 rows of the data. Scroll left and right to see all the columns. Then change the number and re-run the code to see what it does.</mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fraud</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>...</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6398.0</td>\n",
       "      <td>-2.380210</td>\n",
       "      <td>-0.266473</td>\n",
       "      <td>1.090077</td>\n",
       "      <td>0.853215</td>\n",
       "      <td>3.371780</td>\n",
       "      <td>3.790719</td>\n",
       "      <td>-1.123674</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.223553</td>\n",
       "      <td>-0.671187</td>\n",
       "      <td>-0.306571</td>\n",
       "      <td>-0.514617</td>\n",
       "      <td>-0.443708</td>\n",
       "      <td>0.962374</td>\n",
       "      <td>0.088245</td>\n",
       "      <td>-0.280859</td>\n",
       "      <td>-0.635895</td>\n",
       "      <td>0.616903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>168.08</td>\n",
       "      <td>144368.0</td>\n",
       "      <td>-0.501770</td>\n",
       "      <td>0.512773</td>\n",
       "      <td>-0.494351</td>\n",
       "      <td>-0.657718</td>\n",
       "      <td>0.695019</td>\n",
       "      <td>0.974452</td>\n",
       "      <td>1.482355</td>\n",
       "      <td>...</td>\n",
       "      <td>1.298452</td>\n",
       "      <td>-0.274723</td>\n",
       "      <td>-0.001963</td>\n",
       "      <td>0.251114</td>\n",
       "      <td>-0.169487</td>\n",
       "      <td>-0.454563</td>\n",
       "      <td>-0.184577</td>\n",
       "      <td>-0.298358</td>\n",
       "      <td>0.042771</td>\n",
       "      <td>0.108608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>6.63</td>\n",
       "      <td>48330.0</td>\n",
       "      <td>-2.031128</td>\n",
       "      <td>1.253731</td>\n",
       "      <td>1.070599</td>\n",
       "      <td>0.359631</td>\n",
       "      <td>0.434048</td>\n",
       "      <td>-0.799150</td>\n",
       "      <td>1.256107</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.154391</td>\n",
       "      <td>-0.288509</td>\n",
       "      <td>0.059160</td>\n",
       "      <td>0.424752</td>\n",
       "      <td>-0.304448</td>\n",
       "      <td>0.413236</td>\n",
       "      <td>0.080387</td>\n",
       "      <td>-0.636258</td>\n",
       "      <td>-2.489246</td>\n",
       "      <td>-0.544980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>10.07</td>\n",
       "      <td>13291.0</td>\n",
       "      <td>-1.194486</td>\n",
       "      <td>0.917545</td>\n",
       "      <td>1.769059</td>\n",
       "      <td>-0.833028</td>\n",
       "      <td>-0.296318</td>\n",
       "      <td>-0.324340</td>\n",
       "      <td>-0.159088</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.906351</td>\n",
       "      <td>-0.058228</td>\n",
       "      <td>-0.151858</td>\n",
       "      <td>-0.358540</td>\n",
       "      <td>0.082015</td>\n",
       "      <td>0.180577</td>\n",
       "      <td>-0.488772</td>\n",
       "      <td>0.615896</td>\n",
       "      <td>0.119299</td>\n",
       "      <td>0.061904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>49.08</td>\n",
       "      <td>24430.0</td>\n",
       "      <td>-1.258770</td>\n",
       "      <td>1.011808</td>\n",
       "      <td>1.134976</td>\n",
       "      <td>-1.716026</td>\n",
       "      <td>0.025043</td>\n",
       "      <td>-1.145037</td>\n",
       "      <td>1.170804</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.910318</td>\n",
       "      <td>0.032569</td>\n",
       "      <td>-0.295435</td>\n",
       "      <td>-0.087037</td>\n",
       "      <td>0.206569</td>\n",
       "      <td>0.362216</td>\n",
       "      <td>-1.164668</td>\n",
       "      <td>0.273269</td>\n",
       "      <td>-0.315072</td>\n",
       "      <td>0.040467</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Fraud  Amount      Time        V1        V2        V3        V4        V5  \\\n",
       "0      0    0.00    6398.0 -2.380210 -0.266473  1.090077  0.853215  3.371780   \n",
       "1      0  168.08  144368.0 -0.501770  0.512773 -0.494351 -0.657718  0.695019   \n",
       "2      0    6.63   48330.0 -2.031128  1.253731  1.070599  0.359631  0.434048   \n",
       "3      0   10.07   13291.0 -1.194486  0.917545  1.769059 -0.833028 -0.296318   \n",
       "4      0   49.08   24430.0 -1.258770  1.011808  1.134976 -1.716026  0.025043   \n",
       "\n",
       "         V6        V7  ...       V19       V20       V21       V22       V23  \\\n",
       "0  3.790719 -1.123674  ... -1.223553 -0.671187 -0.306571 -0.514617 -0.443708   \n",
       "1  0.974452  1.482355  ...  1.298452 -0.274723 -0.001963  0.251114 -0.169487   \n",
       "2 -0.799150  1.256107  ... -0.154391 -0.288509  0.059160  0.424752 -0.304448   \n",
       "3 -0.324340 -0.159088  ... -0.906351 -0.058228 -0.151858 -0.358540  0.082015   \n",
       "4 -1.145037  1.170804  ... -1.910318  0.032569 -0.295435 -0.087037  0.206569   \n",
       "\n",
       "        V24       V25       V26       V27       V28  \n",
       "0  0.962374  0.088245 -0.280859 -0.635895  0.616903  \n",
       "1 -0.454563 -0.184577 -0.298358  0.042771  0.108608  \n",
       "2  0.413236  0.080387 -0.636258 -2.489246 -0.544980  \n",
       "3  0.180577 -0.488772  0.615896  0.119299  0.061904  \n",
       "4  0.362216 -1.164668  0.273269 -0.315072  0.040467  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<mark>Run the code below to see summary statistics for the entire dataset. Can you find the average amount of the transactions in this dataset?</mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fraud</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>...</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>179807.000000</td>\n",
       "      <td>179807.000000</td>\n",
       "      <td>179807.000000</td>\n",
       "      <td>179807.000000</td>\n",
       "      <td>179807.000000</td>\n",
       "      <td>179807.000000</td>\n",
       "      <td>179807.000000</td>\n",
       "      <td>179807.000000</td>\n",
       "      <td>179807.000000</td>\n",
       "      <td>179807.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>179807.000000</td>\n",
       "      <td>179807.000000</td>\n",
       "      <td>179807.000000</td>\n",
       "      <td>179807.000000</td>\n",
       "      <td>179807.000000</td>\n",
       "      <td>179807.000000</td>\n",
       "      <td>179807.000000</td>\n",
       "      <td>179807.000000</td>\n",
       "      <td>179807.000000</td>\n",
       "      <td>179807.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.002736</td>\n",
       "      <td>88.691655</td>\n",
       "      <td>94852.147514</td>\n",
       "      <td>-0.008439</td>\n",
       "      <td>0.005504</td>\n",
       "      <td>-0.010693</td>\n",
       "      <td>0.003398</td>\n",
       "      <td>-0.003956</td>\n",
       "      <td>-0.001342</td>\n",
       "      <td>-0.004055</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000196</td>\n",
       "      <td>0.001023</td>\n",
       "      <td>-0.000759</td>\n",
       "      <td>0.000299</td>\n",
       "      <td>-0.000854</td>\n",
       "      <td>-0.000885</td>\n",
       "      <td>0.000234</td>\n",
       "      <td>0.000931</td>\n",
       "      <td>0.000379</td>\n",
       "      <td>-0.000530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.052238</td>\n",
       "      <td>256.780747</td>\n",
       "      <td>47511.317469</td>\n",
       "      <td>1.990363</td>\n",
       "      <td>1.672807</td>\n",
       "      <td>1.557383</td>\n",
       "      <td>1.427128</td>\n",
       "      <td>1.408462</td>\n",
       "      <td>1.339708</td>\n",
       "      <td>1.290396</td>\n",
       "      <td>...</td>\n",
       "      <td>0.816032</td>\n",
       "      <td>0.786039</td>\n",
       "      <td>0.747883</td>\n",
       "      <td>0.727345</td>\n",
       "      <td>0.622993</td>\n",
       "      <td>0.605972</td>\n",
       "      <td>0.521215</td>\n",
       "      <td>0.483004</td>\n",
       "      <td>0.408920</td>\n",
       "      <td>0.333813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-56.407510</td>\n",
       "      <td>-72.715728</td>\n",
       "      <td>-48.325589</td>\n",
       "      <td>-5.600607</td>\n",
       "      <td>-113.743307</td>\n",
       "      <td>-26.160506</td>\n",
       "      <td>-43.557242</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.213527</td>\n",
       "      <td>-54.497720</td>\n",
       "      <td>-34.830382</td>\n",
       "      <td>-10.933144</td>\n",
       "      <td>-32.828995</td>\n",
       "      <td>-2.836627</td>\n",
       "      <td>-8.696627</td>\n",
       "      <td>-2.604551</td>\n",
       "      <td>-9.895244</td>\n",
       "      <td>-15.430084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.590000</td>\n",
       "      <td>54197.500000</td>\n",
       "      <td>-0.922073</td>\n",
       "      <td>-0.597506</td>\n",
       "      <td>-0.894809</td>\n",
       "      <td>-0.849089</td>\n",
       "      <td>-0.693350</td>\n",
       "      <td>-0.770329</td>\n",
       "      <td>-0.555703</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.455127</td>\n",
       "      <td>-0.211652</td>\n",
       "      <td>-0.228478</td>\n",
       "      <td>-0.543265</td>\n",
       "      <td>-0.162106</td>\n",
       "      <td>-0.355531</td>\n",
       "      <td>-0.316732</td>\n",
       "      <td>-0.326259</td>\n",
       "      <td>-0.071221</td>\n",
       "      <td>-0.053356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>84730.000000</td>\n",
       "      <td>0.013052</td>\n",
       "      <td>0.066827</td>\n",
       "      <td>0.175026</td>\n",
       "      <td>-0.018199</td>\n",
       "      <td>-0.053101</td>\n",
       "      <td>-0.276379</td>\n",
       "      <td>0.040783</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004523</td>\n",
       "      <td>-0.061435</td>\n",
       "      <td>-0.029734</td>\n",
       "      <td>0.007104</td>\n",
       "      <td>-0.011208</td>\n",
       "      <td>0.040260</td>\n",
       "      <td>0.014645</td>\n",
       "      <td>-0.051627</td>\n",
       "      <td>0.001256</td>\n",
       "      <td>0.011036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>77.525000</td>\n",
       "      <td>139459.000000</td>\n",
       "      <td>1.315338</td>\n",
       "      <td>0.807438</td>\n",
       "      <td>1.028009</td>\n",
       "      <td>0.745151</td>\n",
       "      <td>0.614137</td>\n",
       "      <td>0.400072</td>\n",
       "      <td>0.573418</td>\n",
       "      <td>...</td>\n",
       "      <td>0.459585</td>\n",
       "      <td>0.134985</td>\n",
       "      <td>0.186511</td>\n",
       "      <td>0.531050</td>\n",
       "      <td>0.147933</td>\n",
       "      <td>0.439650</td>\n",
       "      <td>0.349949</td>\n",
       "      <td>0.242213</td>\n",
       "      <td>0.091210</td>\n",
       "      <td>0.078259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>25691.160000</td>\n",
       "      <td>172788.000000</td>\n",
       "      <td>2.454930</td>\n",
       "      <td>22.057729</td>\n",
       "      <td>4.226108</td>\n",
       "      <td>16.875344</td>\n",
       "      <td>34.801666</td>\n",
       "      <td>73.301626</td>\n",
       "      <td>120.589494</td>\n",
       "      <td>...</td>\n",
       "      <td>5.591971</td>\n",
       "      <td>39.420904</td>\n",
       "      <td>27.202839</td>\n",
       "      <td>10.503090</td>\n",
       "      <td>22.528412</td>\n",
       "      <td>4.584549</td>\n",
       "      <td>7.519589</td>\n",
       "      <td>3.517346</td>\n",
       "      <td>31.612198</td>\n",
       "      <td>33.847808</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Fraud         Amount           Time             V1  \\\n",
       "count  179807.000000  179807.000000  179807.000000  179807.000000   \n",
       "mean        0.002736      88.691655   94852.147514      -0.008439   \n",
       "std         0.052238     256.780747   47511.317469       1.990363   \n",
       "min         0.000000       0.000000       0.000000     -56.407510   \n",
       "25%         0.000000       5.590000   54197.500000      -0.922073   \n",
       "50%         0.000000      22.000000   84730.000000       0.013052   \n",
       "75%         0.000000      77.525000  139459.000000       1.315338   \n",
       "max         1.000000   25691.160000  172788.000000       2.454930   \n",
       "\n",
       "                  V2             V3             V4             V5  \\\n",
       "count  179807.000000  179807.000000  179807.000000  179807.000000   \n",
       "mean        0.005504      -0.010693       0.003398      -0.003956   \n",
       "std         1.672807       1.557383       1.427128       1.408462   \n",
       "min       -72.715728     -48.325589      -5.600607    -113.743307   \n",
       "25%        -0.597506      -0.894809      -0.849089      -0.693350   \n",
       "50%         0.066827       0.175026      -0.018199      -0.053101   \n",
       "75%         0.807438       1.028009       0.745151       0.614137   \n",
       "max        22.057729       4.226108      16.875344      34.801666   \n",
       "\n",
       "                  V6             V7  ...            V19            V20  \\\n",
       "count  179807.000000  179807.000000  ...  179807.000000  179807.000000   \n",
       "mean       -0.001342      -0.004055  ...       0.000196       0.001023   \n",
       "std         1.339708       1.290396  ...       0.816032       0.786039   \n",
       "min       -26.160506     -43.557242  ...      -7.213527     -54.497720   \n",
       "25%        -0.770329      -0.555703  ...      -0.455127      -0.211652   \n",
       "50%        -0.276379       0.040783  ...       0.004523      -0.061435   \n",
       "75%         0.400072       0.573418  ...       0.459585       0.134985   \n",
       "max        73.301626     120.589494  ...       5.591971      39.420904   \n",
       "\n",
       "                 V21            V22            V23            V24  \\\n",
       "count  179807.000000  179807.000000  179807.000000  179807.000000   \n",
       "mean       -0.000759       0.000299      -0.000854      -0.000885   \n",
       "std         0.747883       0.727345       0.622993       0.605972   \n",
       "min       -34.830382     -10.933144     -32.828995      -2.836627   \n",
       "25%        -0.228478      -0.543265      -0.162106      -0.355531   \n",
       "50%        -0.029734       0.007104      -0.011208       0.040260   \n",
       "75%         0.186511       0.531050       0.147933       0.439650   \n",
       "max        27.202839      10.503090      22.528412       4.584549   \n",
       "\n",
       "                 V25            V26            V27            V28  \n",
       "count  179807.000000  179807.000000  179807.000000  179807.000000  \n",
       "mean        0.000234       0.000931       0.000379      -0.000530  \n",
       "std         0.521215       0.483004       0.408920       0.333813  \n",
       "min        -8.696627      -2.604551      -9.895244     -15.430084  \n",
       "25%        -0.316732      -0.326259      -0.071221      -0.053356  \n",
       "50%         0.014645      -0.051627       0.001256       0.011036  \n",
       "75%         0.349949       0.242213       0.091210       0.078259  \n",
       "max         7.519589       3.517346      31.612198      33.847808  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"background-color:Purple; text-align:center\"><br>Quiz<br></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<h2 style=\"background-color:DodgerBlue; text-align:center\"><br>Step 3: Building our model<br></h2>\n",
    "<br>\n",
    "<b>Mastercard uses a variety of types models as part of Decision Intelligence to detect fraud. One of them is decision trees.</b>\n",
    "\n",
    "<mark>Read the code below and try to understand what it is doing. The greenish gray text after \"#\" are comments - little bits of text to explain the code, they don't do anything other than explain the code. Once you're happy, run the code and hope for no errors!</mark> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the most popular library of code for making decision trees (found by googling)\n",
    "from sklearn import tree\n",
    "\n",
    "# Use all data except the 'Fraud' column as input\n",
    "X = data.drop('Fraud', axis=1)\n",
    "\n",
    "# Use the 'Fraud' column as what we want to predict as output\n",
    "Y = data['Fraud']\n",
    "\n",
    "# Create an empty model \n",
    "model = tree.DecisionTreeClassifier()\n",
    "\n",
    "# Fit the model to our data\n",
    "model = model.fit(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've built our tree -- now let's test it.\n",
    "\n",
    "<mark>Run the code below to evaluate the accuracy of our tree using our input and output data.</mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy ranges between 0.0 (it predicted every transaction wrong) to 1.0 (it predicted every transaction right).\n",
    "\n",
    "<mark>Look at your accuracy and consider: is it possible to be too accurate?</mark>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"background-color:Purple; text-align:center\"><br>Quiz<br></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<h2 style=\"background-color:MediumSeaGreen; text-align:center\"><br>Step 4: Evaluating our model<br></h2>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model iteration\n",
    "\n",
    "Just like much of writing is reading and re-writing, when data scientists build their models, they constantly test and re-build them.\n",
    "\n",
    "<mark>Run the code below to split the data into training X and Y and test X and Y (this creates four sets of data)</mark>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split X and y (our input and outputs) into training and testing datasets.\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=99)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the code we used to build the model before.\n",
    "\n",
    "<mark><b>Modify the code</b> so that it fits on your training data and scores on your testing data. (Hint: look at the code in the cell above)</mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9987950243775837"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tree.DecisionTreeClassifier()\n",
    "model = model.fit(X_train, Y_train)\n",
    "model.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, what might explain the accuracy score of your model?\n",
    "\n",
    "<mark>Run the code below and interpret the results. What problem is this showing?</mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    179315\n",
      "1       492\n",
      "Name: Fraud, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'Frequency of Genuine vs Fraudulent Transactions'}>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "counts = pd.value_counts(data['Fraud'])\n",
    "\n",
    "%matplotlib inline\n",
    "print(counts)\n",
    "counts.plot(kind=\"bar\",\n",
    "           title=\"Frequency of Genuine vs Fraudulent Transactions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why is this a problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"background-color:Purple; text-align:center\"><br>Quiz<br></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<h2 style=\"background-color:DarkOrange; text-align:center\"><br>Step 5: Improving our model<br></h2>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforming the data\n",
    "\n",
    "**Data scientists make choices that impact model outputs. At Mastercard, data scientists are dealing with the same challenge: trying to reduce fraud based on limited datasets.**\n",
    "\n",
    "To deal with the uneven number of fraud and genuine transactions, we could artificially increase the number of fraud transactions by creating similar transactions, or we could reduce the number of genuine transactions.\n",
    "\n",
    "With more time, we might test multiple strategies. Today we'll just try reducing the number of genuine transactions.\n",
    "\n",
    "<mark>Run the code, and look at the mean of the Class column. What does it mean? <b>Modify number_genuine to change the number of genuine transactions that balance the classes, and re-run the code</b>.</mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fraud</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>...</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>992.000000</td>\n",
       "      <td>992.000000</td>\n",
       "      <td>992.000000</td>\n",
       "      <td>992.000000</td>\n",
       "      <td>992.000000</td>\n",
       "      <td>992.000000</td>\n",
       "      <td>992.000000</td>\n",
       "      <td>992.000000</td>\n",
       "      <td>992.000000</td>\n",
       "      <td>992.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>992.000000</td>\n",
       "      <td>992.000000</td>\n",
       "      <td>992.000000</td>\n",
       "      <td>992.000000</td>\n",
       "      <td>992.000000</td>\n",
       "      <td>992.000000</td>\n",
       "      <td>992.000000</td>\n",
       "      <td>992.000000</td>\n",
       "      <td>992.000000</td>\n",
       "      <td>992.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.495968</td>\n",
       "      <td>97.115504</td>\n",
       "      <td>88145.298387</td>\n",
       "      <td>-2.367038</td>\n",
       "      <td>1.826293</td>\n",
       "      <td>-3.471233</td>\n",
       "      <td>2.221767</td>\n",
       "      <td>-1.537400</td>\n",
       "      <td>-0.681850</td>\n",
       "      <td>-2.765993</td>\n",
       "      <td>...</td>\n",
       "      <td>0.349127</td>\n",
       "      <td>0.180894</td>\n",
       "      <td>0.355006</td>\n",
       "      <td>-0.001476</td>\n",
       "      <td>0.000947</td>\n",
       "      <td>-0.041623</td>\n",
       "      <td>0.024428</td>\n",
       "      <td>0.036707</td>\n",
       "      <td>0.082609</td>\n",
       "      <td>0.026920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.500236</td>\n",
       "      <td>210.134612</td>\n",
       "      <td>49317.453562</td>\n",
       "      <td>5.498182</td>\n",
       "      <td>3.650224</td>\n",
       "      <td>6.224178</td>\n",
       "      <td>3.212895</td>\n",
       "      <td>4.198582</td>\n",
       "      <td>1.744242</td>\n",
       "      <td>5.826678</td>\n",
       "      <td>...</td>\n",
       "      <td>1.266896</td>\n",
       "      <td>1.067178</td>\n",
       "      <td>2.785511</td>\n",
       "      <td>1.162077</td>\n",
       "      <td>1.186863</td>\n",
       "      <td>0.562276</td>\n",
       "      <td>0.664691</td>\n",
       "      <td>0.480077</td>\n",
       "      <td>1.023689</td>\n",
       "      <td>0.428831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>194.000000</td>\n",
       "      <td>-30.552380</td>\n",
       "      <td>-14.007366</td>\n",
       "      <td>-31.103685</td>\n",
       "      <td>-4.293489</td>\n",
       "      <td>-22.105532</td>\n",
       "      <td>-6.406267</td>\n",
       "      <td>-43.557242</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.681904</td>\n",
       "      <td>-9.150864</td>\n",
       "      <td>-22.797604</td>\n",
       "      <td>-8.887017</td>\n",
       "      <td>-19.254328</td>\n",
       "      <td>-2.754889</td>\n",
       "      <td>-4.781606</td>\n",
       "      <td>-1.152671</td>\n",
       "      <td>-7.263482</td>\n",
       "      <td>-2.951213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.630000</td>\n",
       "      <td>45491.500000</td>\n",
       "      <td>-2.784711</td>\n",
       "      <td>-0.179243</td>\n",
       "      <td>-5.074851</td>\n",
       "      <td>-0.151188</td>\n",
       "      <td>-1.777659</td>\n",
       "      <td>-1.551056</td>\n",
       "      <td>-3.060742</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.444147</td>\n",
       "      <td>-0.183981</td>\n",
       "      <td>-0.175062</td>\n",
       "      <td>-0.538291</td>\n",
       "      <td>-0.226725</td>\n",
       "      <td>-0.388661</td>\n",
       "      <td>-0.305828</td>\n",
       "      <td>-0.288700</td>\n",
       "      <td>-0.066137</td>\n",
       "      <td>-0.070073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.595000</td>\n",
       "      <td>81764.000000</td>\n",
       "      <td>-0.821276</td>\n",
       "      <td>0.942592</td>\n",
       "      <td>-1.343919</td>\n",
       "      <td>1.203205</td>\n",
       "      <td>-0.359720</td>\n",
       "      <td>-0.638118</td>\n",
       "      <td>-0.674244</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228437</td>\n",
       "      <td>0.024277</td>\n",
       "      <td>0.130657</td>\n",
       "      <td>0.010791</td>\n",
       "      <td>-0.031389</td>\n",
       "      <td>0.011384</td>\n",
       "      <td>0.038024</td>\n",
       "      <td>0.008494</td>\n",
       "      <td>0.040637</td>\n",
       "      <td>0.030122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>99.990000</td>\n",
       "      <td>137064.250000</td>\n",
       "      <td>1.064858</td>\n",
       "      <td>2.791569</td>\n",
       "      <td>0.363604</td>\n",
       "      <td>4.229802</td>\n",
       "      <td>0.454404</td>\n",
       "      <td>0.089963</td>\n",
       "      <td>0.291366</td>\n",
       "      <td>...</td>\n",
       "      <td>0.992322</td>\n",
       "      <td>0.423209</td>\n",
       "      <td>0.652202</td>\n",
       "      <td>0.548872</td>\n",
       "      <td>0.199231</td>\n",
       "      <td>0.382628</td>\n",
       "      <td>0.401178</td>\n",
       "      <td>0.351076</td>\n",
       "      <td>0.426872</td>\n",
       "      <td>0.209627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2125.870000</td>\n",
       "      <td>171815.000000</td>\n",
       "      <td>2.342166</td>\n",
       "      <td>22.057729</td>\n",
       "      <td>3.114829</td>\n",
       "      <td>12.114672</td>\n",
       "      <td>11.095089</td>\n",
       "      <td>6.474115</td>\n",
       "      <td>5.802537</td>\n",
       "      <td>...</td>\n",
       "      <td>5.228342</td>\n",
       "      <td>11.059004</td>\n",
       "      <td>27.202839</td>\n",
       "      <td>8.361985</td>\n",
       "      <td>9.974239</td>\n",
       "      <td>1.212078</td>\n",
       "      <td>2.261462</td>\n",
       "      <td>2.745261</td>\n",
       "      <td>4.374186</td>\n",
       "      <td>1.779364</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Fraud       Amount           Time          V1          V2  \\\n",
       "count  992.000000   992.000000     992.000000  992.000000  992.000000   \n",
       "mean     0.495968    97.115504   88145.298387   -2.367038    1.826293   \n",
       "std      0.500236   210.134612   49317.453562    5.498182    3.650224   \n",
       "min      0.000000     0.000000     194.000000  -30.552380  -14.007366   \n",
       "25%      0.000000     1.630000   45491.500000   -2.784711   -0.179243   \n",
       "50%      0.000000    19.595000   81764.000000   -0.821276    0.942592   \n",
       "75%      1.000000    99.990000  137064.250000    1.064858    2.791569   \n",
       "max      1.000000  2125.870000  171815.000000    2.342166   22.057729   \n",
       "\n",
       "               V3          V4          V5          V6          V7  ...  \\\n",
       "count  992.000000  992.000000  992.000000  992.000000  992.000000  ...   \n",
       "mean    -3.471233    2.221767   -1.537400   -0.681850   -2.765993  ...   \n",
       "std      6.224178    3.212895    4.198582    1.744242    5.826678  ...   \n",
       "min    -31.103685   -4.293489  -22.105532   -6.406267  -43.557242  ...   \n",
       "25%     -5.074851   -0.151188   -1.777659   -1.551056   -3.060742  ...   \n",
       "50%     -1.343919    1.203205   -0.359720   -0.638118   -0.674244  ...   \n",
       "75%      0.363604    4.229802    0.454404    0.089963    0.291366  ...   \n",
       "max      3.114829   12.114672   11.095089    6.474115    5.802537  ...   \n",
       "\n",
       "              V19         V20         V21         V22         V23         V24  \\\n",
       "count  992.000000  992.000000  992.000000  992.000000  992.000000  992.000000   \n",
       "mean     0.349127    0.180894    0.355006   -0.001476    0.000947   -0.041623   \n",
       "std      1.266896    1.067178    2.785511    1.162077    1.186863    0.562276   \n",
       "min     -3.681904   -9.150864  -22.797604   -8.887017  -19.254328   -2.754889   \n",
       "25%     -0.444147   -0.183981   -0.175062   -0.538291   -0.226725   -0.388661   \n",
       "50%      0.228437    0.024277    0.130657    0.010791   -0.031389    0.011384   \n",
       "75%      0.992322    0.423209    0.652202    0.548872    0.199231    0.382628   \n",
       "max      5.228342   11.059004   27.202839    8.361985    9.974239    1.212078   \n",
       "\n",
       "              V25         V26         V27         V28  \n",
       "count  992.000000  992.000000  992.000000  992.000000  \n",
       "mean     0.024428    0.036707    0.082609    0.026920  \n",
       "std      0.664691    0.480077    1.023689    0.428831  \n",
       "min     -4.781606   -1.152671   -7.263482   -2.951213  \n",
       "25%     -0.305828   -0.288700   -0.066137   -0.070073  \n",
       "50%      0.038024    0.008494    0.040637    0.030122  \n",
       "75%      0.401178    0.351076    0.426872    0.209627  \n",
       "max      2.261462    2.745261    4.374186    1.779364  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many genuine transactions should we use to balance the classes?\n",
    "number_genuine = 500\n",
    "\n",
    "# Separate genuine transactions and fraud\n",
    "genuine = data[data['Fraud'] == 0].sample(number_genuine)\n",
    "fraud = data[data['Fraud'] == 1]\n",
    "\n",
    "# Combine fraud and genuine\n",
    "even_data = pd.concat([genuine, fraud])\n",
    "\n",
    "# Summarize our new dataset, even_data\n",
    "even_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have a new dataset, we'll need to recreate our inputs, outputs, and split them into training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9026845637583892"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create inputs and outputs with new dataset\n",
    "X = even_data.drop('Fraud', axis=1)\n",
    "Y = even_data['Fraud']\n",
    "\n",
    "# Split new inputs and outputs into training and testing\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=99)\n",
    "\n",
    "# Train and score decision tree using new data\n",
    "model = tree.DecisionTreeClassifier(max_depth = 1)\n",
    "model = model.fit(X_train, Y_train)\n",
    "model.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last step is to visualize the decision tree we made. To do this, we've copied some code from the sklearn documentation.\n",
    "\n",
    "<mark>Run the code below to see your tree!</mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.44.1 (20200629.0846)\n",
       " -->\n",
       "<!-- Title: Tree Pages: 1 -->\n",
       "<svg width=\"254pt\" height=\"195pt\"\n",
       " viewBox=\"0.00 0.00 253.50 195.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 191)\">\n",
       "<title>Tree</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-191 249.5,-191 249.5,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<path fill=\"#fdf7f3\" stroke=\"black\" d=\"M171.5,-187C171.5,-187 70.5,-187 70.5,-187 64.5,-187 58.5,-181 58.5,-175 58.5,-175 58.5,-116 58.5,-116 58.5,-110 64.5,-104 70.5,-104 70.5,-104 171.5,-104 171.5,-104 177.5,-104 183.5,-110 183.5,-116 183.5,-116 183.5,-175 183.5,-175 183.5,-181 177.5,-187 171.5,-187\"/>\n",
       "<text text-anchor=\"start\" x=\"82\" y=\"-171.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">V14 ≤ &#45;1.778</text>\n",
       "<text text-anchor=\"start\" x=\"85.5\" y=\"-156.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.499</text>\n",
       "<text text-anchor=\"start\" x=\"76\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 694</text>\n",
       "<text text-anchor=\"start\" x=\"66.5\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [358, 336]</text>\n",
       "<text text-anchor=\"start\" x=\"71.5\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = Genuine</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>1</title>\n",
       "<path fill=\"#3c9ee5\" stroke=\"black\" d=\"M98,-68C98,-68 12,-68 12,-68 6,-68 0,-62 0,-56 0,-56 0,-12 0,-12 0,-6 6,0 12,0 12,0 98,0 98,0 104,0 110,-6 110,-12 110,-12 110,-56 110,-56 110,-62 104,-68 98,-68\"/>\n",
       "<text text-anchor=\"start\" x=\"19.5\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.026</text>\n",
       "<text text-anchor=\"start\" x=\"10\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 298</text>\n",
       "<text text-anchor=\"start\" x=\"8\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [4, 294]</text>\n",
       "<text text-anchor=\"start\" x=\"14\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = Fraud</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M96.42,-103.73C91.15,-94.97 85.56,-85.7 80.26,-76.91\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"83.23,-75.06 75.07,-68.3 77.24,-78.67 83.23,-75.06\"/>\n",
       "<text text-anchor=\"middle\" x=\"69.06\" y=\"-88.87\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">True</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2</title>\n",
       "<path fill=\"#e89050\" stroke=\"black\" d=\"M233.5,-68C233.5,-68 140.5,-68 140.5,-68 134.5,-68 128.5,-62 128.5,-56 128.5,-56 128.5,-12 128.5,-12 128.5,-6 134.5,0 140.5,0 140.5,0 233.5,0 233.5,0 239.5,0 245.5,-6 245.5,-12 245.5,-12 245.5,-56 245.5,-56 245.5,-62 239.5,-68 233.5,-68\"/>\n",
       "<text text-anchor=\"start\" x=\"155\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.19</text>\n",
       "<text text-anchor=\"start\" x=\"142\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 396</text>\n",
       "<text text-anchor=\"start\" x=\"136.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [354, 42]</text>\n",
       "<text text-anchor=\"start\" x=\"137.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = Genuine</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>0&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M145.58,-103.73C150.85,-94.97 156.44,-85.7 161.74,-76.91\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"164.76,-78.67 166.93,-68.3 158.77,-75.06 164.76,-78.67\"/>\n",
       "<text text-anchor=\"middle\" x=\"172.94\" y=\"-88.87\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">False</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x129b3ca90>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import graphviz\n",
    "dot_data = tree.export_graphviz(model, out_file=None, \n",
    "                     feature_names=X.columns.values,  \n",
    "                     class_names=[\"Genuine\",\"Fraud\"],  \n",
    "                     filled=True, rounded=True, \n",
    "                     special_characters=True)  \n",
    "graph = graphviz.Source(dot_data)  \n",
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might notice your decision tree is very small. The final step is to evaluate how complex your decision tree needs to be.\n",
    "\n",
    "<mark>Go back <b>two</b> code cells and change the max_depth of your decsion tree (line 9). Run the code, then re-run the code to visualize the tree</mark>\n",
    "\n",
    "<mark>What size of decision tree gets the greatest accuracy for your data? Why?</mark>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<h2 style=\"background-color:Gold; text-align:center\"><br>Step 6: Quantifying the investment<br></h2>\n",
    "<br>\n",
    "\n",
    "**Building good models requires time and resources; it is important to focus on valuable investments.**\n",
    "\n",
    "How do you know your time was well spent?\n",
    "\n",
    "There are huge costs associated with accepting a fraudlent transaction; [LexisNexis](https://risk.lexisnexis.com/insights-resources/research/2018-true-cost-of-fraud-study-for-the-retail-sector) finds fraud costs retailers an average of $2.94 per fraudulent dollar in fees, prevention, legal costs, etc. Declining a genuine transaction is costly too! [Ayden and 451 Research](https://go.adyen.com/rs/222-DNK-376/images/Retail%20Report%202019.pdf?mkt_tok=eyJpIjoiWXpNeE56Y3paRGszTnpBNSIsInQiOiJaVmJ1NXVJVkZFMkdHY1FCYVRGUENFemlDWnU3RSthM21LRmF3MDdtUldwSjZvMVF6ZzVjTTFjemJKS1BxZUJWWElxejZrQXVKeDhwNlZGVXkwT3FtcTkwd1BFTkwwaWZlV1BFcnM3YmY2aEQ1RnMrT3BFS1g4MTRsaWI3R1BUSSJ9) report 2 in 5 consumers have abandoned a purchase after a declined payment in the past 6 months. Customers are less likely to return to a merchant after a failed payment.\n",
    "\n",
    "In our simulation, we'll charge $2.94 per dollar for each false approval and the cost of the transaction for each false decline. Of course, every situation is different, and a client will likely have their own costs associated with false approvals and declines.\n",
    "\n",
    "<mark>Run the cell below to compare the cost of fraud when using your model with the cost of approving all transactions.</mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You processed 298 payments. 269 were correct predictions, of which the genuine transactions totalled $8695.19 in revenue.\n",
      "\n",
      "You had 21 false approvals, which cost $5557.57 in fees and administrative costs.\n",
      "You had 8 false declines, which cost $85.01 in missed sales.\n",
      "\n",
      "If you had simply approved all 298 transactions, you would have falsely approved 156 transactions, costing $49248.41 while earning $8780.2 in revenue.\n",
      "\n",
      "Your model's predictions were worth $43520.82.\n"
     ]
    }
   ],
   "source": [
    "COST_PER_FRAUD_DOLLAR = 2.94 # Cost per dollar of a false approval\n",
    "COST_PER_FALSE_DECLINE_DOLLAR = 1 # Cost per dollar of a false decline\n",
    "\n",
    "predictions = list(model.predict(X_test))\n",
    "truth = list(Y_test)\n",
    "\n",
    "false_approval_cost = 0\n",
    "false_approval_num = 0\n",
    "false_decline_cost = 0\n",
    "false_decline_num = 0\n",
    "correct_num = 0\n",
    "correct_cost = 0\n",
    "\n",
    "for i in range(len(predictions)):\n",
    "    if predictions[i] != truth[i]: # If our prediction was wrong\n",
    "        if truth[i] == 1: # If we falsely approved\n",
    "            false_approval_cost += (X_test.iloc[i, 0] * COST_PER_FRAUD_DOLLAR) # Cost increases by $2.94 * the amount of the transaction\n",
    "            false_approval_num += 1\n",
    "        else: # If we falsely decline\n",
    "            false_decline_cost += (X_test.iloc[i, 0] * COST_PER_FALSE_DECLINE_DOLLAR) # We miss a sale, cost increases by the amount of the transaction\n",
    "            false_decline_num += 1\n",
    "    else: # If our prediction was correct\n",
    "        correct_num += 1\n",
    "        if truth[i] == 0: # It's a genuine transaction\n",
    "            correct_cost += X_test.iloc[i, 0]\n",
    "print(\"You processed {} payments. {} were correct predictions, of which the genuine transactions totalled ${} in revenue.\\n\\nYou had {} false approvals, which cost ${} in fees and administrative costs.\\nYou had {} false declines, which cost ${} in missed sales.\\n\".format(len(predictions), correct_num, round(correct_cost,2),  false_approval_num, round(false_approval_cost, 2), false_decline_num, round(false_decline_cost,2)))\n",
    "\n",
    "approve_all_cost = 0\n",
    "approve_all_num = 0\n",
    "all_genuine_cost = 0\n",
    "\n",
    "for i in range(len(truth)):\n",
    "    if truth[i] == 1: # There was fraud\n",
    "        approve_all_cost += (X_test.iloc[i, 0] * COST_PER_FRAUD_DOLLAR)\n",
    "        approve_all_num += 1\n",
    "    else: # Genuine transaction\n",
    "        all_genuine_cost += X_test.iloc[i, 0]\n",
    "\n",
    "print(\"If you had simply approved all {} transactions, you would have falsely approved {} transactions, costing ${} while earning ${} in revenue.\\n\".format(len(predictions), approve_all_num, round(approve_all_cost, 2), round(all_genuine_cost, 2)))\n",
    "print(\"Your model's predictions were worth ${}.\".format(round(((correct_cost - false_decline_cost - false_approval_cost)-(all_genuine_cost - approve_all_cost)),2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<mark>What differs in our simulation when compared to reality?</mark>\n",
    "\n",
    "<mark>What could make our model stronger?</mark>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"background-color:Purple; text-align:center\"><br>Quiz<br></h2>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
